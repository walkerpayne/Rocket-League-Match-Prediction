{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to use a dataset that was scraped from Ballchasing.com to programmatically parse user profiles on Rocketleague.tracker.network to gather player stats.\n",
    "- Read in ballchasing data to dataframe\n",
    "- iterate through each game and send the name of the player to RL Tracker. Look up the player via steam ID or xbox/psn name\n",
    "- grab stats from profile - lifetime wins, goal/shot ratio, 1v1 rating (MMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballchasing = pd.read_excel('Ballchasing_data_Nov-01-2021.xlsx', index_col = 0, dtype = {'player2_steam_id':'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/67209947/python-cant-scrape-data-from-my-targeted-site-anymore-using-re-requests-and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:87.0) Gecko/20100101 Firefox/87.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the dataframe and grab p1 steam id, request the webpage, save the data to columns p1_wins, p1_goalshot_ratio, p1_mmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://api.tracker.gg/api/v2/rocket-league/standard/profile/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballchasing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballchasing['p1_profile'] = base_url + 'steam/' + ballchasing['player1_steam_id'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballchasing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_url_list = ballchasing['p1_profile'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using that list, iterate over it and get response from website and get data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p1_wins_list = []\n",
    "p1_mmr = []\n",
    "p1_gs_ratio = []\n",
    "num_loops = 0\n",
    "\n",
    "#for each player profile in the list:\n",
    "for i in range(len(p1_url_list)):\n",
    "    \n",
    "    # get the response for each player profile\n",
    "    response = requests.get(p1_url_list[i], headers=headers)\n",
    "    \n",
    "    # if the page doesnt exist (profile is private, deleted, etc.), append \"null\" for each stat and skip to next iteration\n",
    "    if response.status_code != 200:\n",
    "        p1_wins_list.append('null')\n",
    "        p1_mmr.append('null')\n",
    "        p1_gs_ratio.append('null')\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    # if it does exist, format data as json and append each of the stats to their own list\n",
    "    data = response.json()\n",
    "    p1_wins_list.append(data['data']['segments'][0]['stats']['wins']['value'])\n",
    "    try:\n",
    "        p1_mmr.append(data['data']['segments'][2]['stats']['rating']['value'])\n",
    "    except IndexError:\n",
    "        p1_mmr.append('null')\n",
    "    p1_gs_ratio.append(round(data['data']['segments'][0]['stats']['goalShotRatio']['value'], 2))\n",
    "    \n",
    "    print(num_loops)\n",
    "    num_loops += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that i have p1 stats, I can append them to the df as a column and then go get p2 stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballchasing['p1_wins'] = p1_wins_list\n",
    "ballchasing['p1_mmr'] = p1_mmr\n",
    "ballchasing['p1_gs_ratio'] = p1_gs_ratio\n",
    "#wont work until I fully run the loop and get every piece of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get p2 stats - trickier now, because I don't have a steam ID - will have to construct a list of URLs with their platform and username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballchasing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballchasing['p2_profile'] = np.where(ballchasing['player2_platform'] == 'steam', base_url + 'steam/' + ballchasing['player2_steam_id'].map(str),'null')\n",
    "\n",
    "ballchasing['p2_profile'] = np.where(ballchasing['player2_platform'] == 'xbox', base_url + 'xbox/' + ballchasing['player2_name'],ballchasing['p2_profile'])\n",
    "\n",
    "ballchasing['p2_profile'] = np.where(ballchasing['player2_platform'] == 'epic', base_url + 'epic/' + ballchasing['player2_name'],ballchasing['p2_profile'])\n",
    "\n",
    "ballchasing['p2_profile'] = np.where(ballchasing['player2_platform'] == 'ps4', base_url + 'ps4/' + ballchasing['player2_name'],ballchasing['p2_profile'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballchasing['p2_profile'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_url_list = ballchasing['p2_profile'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat code from above but for p2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_wins_list = []\n",
    "p2_mmr = []\n",
    "p2_gs_ratio = []\n",
    "num_loops = 0\n",
    "\n",
    "#for each player profile in the list:\n",
    "for i in range(len(p2_url_list)):\n",
    "    \n",
    "    if p2_url_list[i] == 'null':\n",
    "        p2_wins_list.append('null')\n",
    "        p2_mmr.append('null')\n",
    "        p2_gs_ratio.append('null')\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        # get the response for each player profile\n",
    "        response = requests.get(p2_url_list[i], headers=headers)\n",
    "\n",
    "        # if the page doesnt exist (profile is private, deleted, etc.), append \"null\" for each stat and skip to next iteration\n",
    "        if response.status_code != 200:\n",
    "            p2_wins_list.append('null')\n",
    "            p2_mmr.append('null')\n",
    "            p2_gs_ratio.append('null')\n",
    "            print(response.status_code)\n",
    "            continue\n",
    "\n",
    "        # if it does exist, format data as json and append each of the stats to their own list\n",
    "        data = response.json()\n",
    "        p2_wins_list.append(data['data']['segments'][0]['stats']['wins']['value'])\n",
    "        try:\n",
    "            p2_mmr.append(data['data']['segments'][2]['stats']['rating']['value'])\n",
    "        except IndexError:\n",
    "            p2_mmr.append('null')\n",
    "        p2_gs_ratio.append(round(data['data']['segments'][0]['stats']['goalShotRatio']['value'], 2))\n",
    "\n",
    "        print(num_loops)\n",
    "        num_loops += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then take the lists and add them to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballchasing['p2_wins'] = p2_wins_list\n",
    "ballchasing['p2_mmr'] = p2_mmr\n",
    "ballchasing['p2_gs_ratio'] = p2_gs_ratio\n",
    "#wont work until you fully run the loop and get every piece of data so that list lengths match."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
